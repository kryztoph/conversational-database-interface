# PostgreSQL Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=cgiuser
POSTGRES_PASSWORD=cgipass
POSTGRES_DB=cgidb

# Llama.cpp Server Configuration
LLAMA_API_URL=http://localhost:8080
LLAMA_PORT=8080

# Model Configuration
# Path to directory containing your GGUF model files
MODEL_PATH=./models

# Name of the model file (e.g., model-name-Q4_K_M.gguf)
MODEL_FILE=model.gguf

# Context size (number of tokens)
CONTEXT_SIZE=4096

# Number of GPU layers to offload (0 = CPU only)
# Set higher values if you have a GPU
GPU_LAYERS=0

# Embedding Model for RAG
# Options: all-MiniLM-L6-v2 (384 dim), all-mpnet-base-v2 (768 dim)
EMBEDDING_MODEL=all-MiniLM-L6-v2
